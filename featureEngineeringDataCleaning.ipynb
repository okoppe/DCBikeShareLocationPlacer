{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9140c324-19b5-4e08-a20c-fde02391412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark://notch082.ipoib.int.chpc.utah.edu:7077\n"
     ]
    }
   ],
   "source": [
    "!echo $SPARK_MASTER_ADDRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56930c31-e6ed-4371-ad6a-7b084238b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, avg, max, min, sum, col, when, to_timestamp, isnan, coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238cda6e-99ce-4e77-8022-ed4494e6c1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/29 21:01:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Open the Spark Session\n",
    "spark =SparkSession.builder.master(os.getenv('SPARK_MASTER_ADDRESS')).appName(\"Spark-application\").getOrCreate()\n",
    "sc = spark._jsc.sc()\n",
    "n_workers = len([executor.host() for executor in\n",
    "sc.statusTracker().getExecutorInfos() ]) -1 \n",
    "print(n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a810ddb7-b752-4225-8334-7c58d502bf6a",
   "metadata": {},
   "source": [
    "### Read in the CSV data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f2b11a2-10a4-430a-951e-69751771492a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rideData = spark.read.csv(\"bike_share_data/mergedRideData.csv\", header=True, inferSchema=True)\n",
    "bikeShareLocations = spark.read.csv(\"bike_share_data/Capital_Bikeshare_Locations.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a9a8c-9e1b-448a-a4c3-4e425a245a6e",
   "metadata": {},
   "source": [
    "### Convert time col's to timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a696d9a-69a8-4489-b993-abac9143e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "rideData = rideData.withColumn(\"started_at\", to_timestamp(\"started_at\"))\n",
    "rideData = rideData.withColumn(\"ended_at\", to_timestamp(\"ended_at\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980aa10f-e880-48b4-9a9d-29f16384df51",
   "metadata": {},
   "source": [
    "### Compute the average length of a ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e032a4-a1ce-45a1-8eaf-5995938e6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "rideData = rideData.withColumn(\"ride_length\", (col(\"ended_at\") - col(\"started_at\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f83b5-824f-470c-824a-e95fcab71f92",
   "metadata": {},
   "source": [
    "### Create binary col for if the ride was done by a member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487534e0-2b06-464d-a92f-931bedb455a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rideData = rideData.withColumn(\"member_binary\", when(col(\"member_casual\") == \"member\", 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96361a2d-a0c8-409c-a6dc-1d95f2a53cee",
   "metadata": {},
   "source": [
    "### Group by start and end station and compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab7c4df-5827-4564-b8d0-d98cea0029e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_station_ride_duration = rideData.groupBy(\"start_station_name\").agg({\"ride_length\": \"avg\"})\n",
    "rides_starting_at = rideData.groupBy(\"start_station_name\").count()\n",
    "rides_starting_at_member = rideData.groupBy(\"start_station_name\").sum(\"member_binary\")\n",
    "\n",
    "end_station_ride_duration = rideData.groupBy(\"end_station_name\").agg({\"ride_length\": \"avg\"})\n",
    "rides_ending_at = rideData.groupBy(\"end_station_name\").count()\n",
    "rides_ending_at_member = rideData.groupBy(\"end_station_name\").sum(\"member_binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc3f67-8340-404b-b3f6-b92cf8c5bbb2",
   "metadata": {},
   "source": [
    "### Create start and end feature data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f42b1f79-257a-4553-b247-5950cfd0ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_starting_at_features = start_station_ride_duration \\\n",
    "    .withColumnRenamed(\"avg(ride_length)\", \"starting_at_avg_ride_duration\") \\\n",
    "    .join(rides_starting_at.withColumnRenamed(\"count\", \"count_rides_starting_at\"), \"start_station_name\") \\\n",
    "    .join(rides_starting_at_member.withColumnRenamed('sum(member_binary)', 'count_of_member_rides_starting_at'), \"start_station_name\")\n",
    "\n",
    "rides_ending_at_features = end_station_ride_duration \\\n",
    "    .withColumnRenamed(\"avg(ride_length)\", \"ending_at_avg_ride_duration\") \\\n",
    "    .join(rides_ending_at.withColumnRenamed(\"count\", \"count_rides_ending_at\"), \"end_station_name\") \\\n",
    "    .join(rides_ending_at_member.withColumnRenamed('sum(member_binary)', 'count_of_member_rides_ending_at'), \"end_station_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264eb29-0caa-4899-9680-b64bed77907e",
   "metadata": {},
   "source": [
    "### Merge the start and end features into one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ad16ca6-2eca-432e-b99b-af8c0b0d43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = rides_starting_at_features.join(rides_ending_at_features, rides_starting_at_features.start_station_name == rides_ending_at_features.end_station_name, how='fullouter')\n",
    "\n",
    "# create one station name column\n",
    "all_features = all_features.withColumn(\"station_name\", coalesce(all_features.start_station_name, all_features.end_station_name))\n",
    "\n",
    "# drop the old station name cols\n",
    "all_features = all_features.drop(*['end_station_name', 'start_station_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9da3d-e349-44d8-a206-e368ef3cd89e",
   "metadata": {},
   "source": [
    "### Clean the bike share stations data set\n",
    "There are several columns that don't provide any value for our model. Drop those columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "945b3469-9542-4c75-a840-895cbf61e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['STATION_STATUS', 'X', 'Y', 'STATION_TYPE', 'STATION_STATUS', 'LAST_REPORTED', 'IS_INSTALLED', 'IS_RETURNING',\n",
    "               'REGION_NAME', 'RENTAL_METHODS', 'REGION_ID', 'GIS_ID', 'GIS_LAST_MOD_DTTM']\n",
    "\n",
    "bikeShareLocations = bikeShareLocations.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11793333-4a96-458c-b7b7-28b4c0d45a7d",
   "metadata": {},
   "source": [
    "### Combine the bike share stations and features data set\n",
    "This will drop all the stations in the features data set that no longer exist in DC (38 stations were removed in 2023/24).\n",
    "These stations and their rides will be dropped from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "928bd271-451b-4974-82dc-699599c96861",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = bikeShareLocations.join(all_features, bikeShareLocations.NAME==all_features.station_name, how='inner')\n",
    "# remove duplicate station name column\n",
    "cleaned_dataset = cleaned_dataset.drop(\"NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb78b4-07fc-4166-aee7-af18f894a2fe",
   "metadata": {},
   "source": [
    "### Create a weight for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "482dafb6-4a35-4ff2-a82b-99532f0349e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = cleaned_dataset.withColumn(\"weight\",\n",
    "    (col(\"count_rides_ending_at\") - col(\"count_of_member_rides_ending_at\")) +\n",
    "    (col(\"count_rides_starting_at\") - col(\"count_of_member_rides_starting_at\")) +\n",
    "    col(\"count_of_member_rides_ending_at\") * 1.25 +\n",
    "    col(\"count_of_member_rides_starting_at\") * 1.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "537998ca-7898-47f1-9483-a4c9066e3ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cleaned_dataset.toPandas().to_csv(\"bike_share_data/cleaned_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
